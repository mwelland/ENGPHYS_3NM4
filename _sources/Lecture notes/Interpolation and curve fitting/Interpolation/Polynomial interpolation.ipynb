{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial interpolation is a straightforward approach to interpolation. \n",
    "\n",
    "Three methods to obtain polynomials are established here. For a given set of data, they all *must* result in the same polynomial. The difference is the means by which they are achieved, which translates to the ways that they are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrange Polynomial Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legendre polynomial interpolation constructs the Legendre polynomial as,\n",
    "$$\n",
    "y(x) = \\sum_{i = 1}^n y_i P_i(x)\n",
    "$$\n",
    "\n",
    "which is a weighted sum of the Lagrange basis polynomials, $P_i(x)$,\n",
    "\n",
    "$$\n",
    "P_i(x) = \\prod_{j = 1, j\\ne i}^n\\frac{x - x_j}{x_i - x_j}.\n",
    "$$\n",
    "\n",
    "N.B.: $\\prod$ means *the product of*, like $\\sum$ means *the sum of*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrange basis polynomials\n",
    "\n",
    "By construction,\n",
    "- $P_i(x_j) = 1$ when $i = j$\n",
    "- $P_i(x_j) = 0$ when $i \\ne j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Find and plot the Lagrange basis polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data:\n",
    "*x = [0, .5, 2]*\n",
    "*y = [1, 3, 2]*\n",
    "\n",
    "\\begin{eqnarray}\n",
    "P_1(x) &=& \\frac{(x - x_2)(x - x_3)}{(x_1-x_2)(x_1-x_3)} = \\frac{(x - 1)(x - 2)}{(0-1)(0-2)} = \\frac{1}{2}(x^2 - 3x + 2),\\\\\n",
    "P_2(x) &=& \\frac{(x - x_1)(x - x_3)}{(x_2-x_1)(x_2-x_3)} = \\frac{(x - 0)(x - 2)}{(1-0)(1-2)} = -x^2 + 2x,\\\\\n",
    "P_3(x) &=& \\frac{(x - x_1)(x - x_2)}{(x_3-x_1)(x_3-x_2)} = \\frac{(x - 0)(x - 1)}{(2-0)(2-1)} = \\frac{1}{2}(x^2 - x).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Plot each polynomial and verify the property that $P_i(x_j) = 1$ when $i = j$ and $P_i(x_j) = 0$ when $i \\ne j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: show me the legendre basis polynomials for the data aove using the numpy.polynomial.legendre Legendre\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial import legendre\n",
    "\n",
    "# Data points\n",
    "x = [0, .5, 2]\n",
    "y = [1, 3, 2]\n",
    "\n",
    "# Calculate the Lagrange basis polynomials\n",
    "n = len(x)\n",
    "P = []\n",
    "for i in range(n):\n",
    "  numerator = 1\n",
    "  denominator = 1\n",
    "  for j in range(n):\n",
    "    if i != j:\n",
    "      numerator = np.polymul(numerator, np.poly1d([1, -x[j]]))\n",
    "      denominator = denominator * (x[i] - x[j])\n",
    "  P.append(np.poly1d(np.polydiv(numerator, denominator)[0]))\n",
    "\n",
    "\n",
    "# Plot the Lagrange basis polynomials\n",
    "x_plot = np.linspace(-1, 3, 100)\n",
    "\n",
    "for i in range(n):\n",
    "    y_plot = P[i](x_plot)\n",
    "    plt.plot(x_plot, y_plot, label=f'P_{i+1}(x)')\n",
    "\n",
    "plt.scatter(x, [1] * len(x), color='black')\n",
    "plt.scatter(x, [0] * len(x), color='red')\n",
    "plt.scatter(x, [0] * len(x), color='red')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('P_i(x)')\n",
    "plt.title('Lagrange Basis Polynomials')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the polynomial\n",
    "\n",
    "Since $P_{i\\ne j}=0$, and $P_{i = j}=1$, it is trivial to see that for $ y(x) = \\sum_{i = 1}^n \\omega_i P_i(x) $, the coefficients are simply:\n",
    "\n",
    "$$\n",
    "y(x) = \\sum_{i = 1}^n y_i P_i(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Plot the legendre polynomial from the basis above\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Construct the Lagrange polynomial\n",
    "L = np.poly1d(0)\n",
    "for i in range(n):\n",
    "  L = L + y[i] * P[i]\n",
    "\n",
    "# Plot the Lagrange polynomial\n",
    "y_plot = L(x_plot)\n",
    "plt.plot(x_plot, y_plot, label='L(x)')\n",
    "plt.scatter(x, y, color='red', label='Data points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('L(x)')\n",
    "plt.title('Lagrange Polynomial Interpolation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe some notes:\n",
    "* For $n$ data points we necessarily produce a unique polynominal that crosses each one.\n",
    "* If we have two measurements at the same input, $x_i = x_j$, $P_i =\\sim \\frac{1}{0}$ which is undefined *unless* $x_i=x_j$ and $y_i=y_j$ in which case the data pair is redundant and can be removed.\n",
    "* Each evalulation of $P(x)$ involves $n-1$ products, and $L(x)$ is the sum of $n$ bases, therefore evaluation is $O(n^2)$\n",
    "* Adding new data means restarting the compuation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Use sympy to fit a lagrange polynomial to the data above (with some extra points)\n",
    "\n",
    "import sympy as sp\n",
    "\n",
    "x = [0, 1, 2, 3, 4]\n",
    "y = [1, 3, 2, 5, 7]\n",
    "\n",
    "n = len(x)\n",
    "x_sym = sp.Symbol('x')\n",
    "\n",
    "L = 0\n",
    "for i in range(n):\n",
    "    term = y[i]\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            term *= (x_sym - x[j]) / (x[i] - x[j])\n",
    "    L += term\n",
    "\n",
    "\n",
    "print(L)\n",
    "\n",
    "print('which is an ugly way of writing out:')\n",
    "print(L.simplify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that the error in the interpolation is,\n",
    "\n",
    "$$\n",
    "y^{true}(x)-y(x) = \\frac{[x-x_1][x-x_2][x-x_3]...[x-x_n]}{(n+1)!} f^{(n+1)}(\\xi)\n",
    "$$\n",
    "\n",
    "where $\\xi$ is in the interval $(x_0, x_n)$.\n",
    "\n",
    "Since for $n$ datapoints there is a unique polynomial of degree $n-1$, which can be expressed as a Lagrange polynomial, **this analysis is universal to all polynomial interpolations!**. The main takeaway is that:\n",
    "\n",
    "*The further a data point is from $x$, the more it contributes to the error.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Barycentric Lagrange Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve the performance of Lagrange Interpolation. Let:\n",
    "\n",
    "$\n",
    "\\Omega(x) = \\prod_{j = 1}^n [x - x_j]\n",
    "$\n",
    "\n",
    "and the *barycentric weights*, $w_i$:\n",
    "\n",
    "$$\n",
    "w_i = \\prod_{j = 1, j\\ne i}^n\\frac{1}{x_i - x_j}.\n",
    "$$\n",
    "\n",
    "and write:\n",
    "\n",
    "$$\n",
    "P_i(x) = \\Omega(x) \\frac{w_i}{x - x_j}.\n",
    "$$\n",
    "\n",
    "and factor the $\\Omega$ out of the sum:\n",
    "\n",
    "$$\n",
    "y(x) = \\Omega(x) \\sum_{j = 1}^n \\frac{w_i}{x - x_j} y_i.\n",
    "$$\n",
    "\n",
    "which is $O(n)$ for evaluation. Calculation of $w_i$ can be formulated recursively, such that each $w_i$ takes $O(n)$ and the full takes $O(n^2)$ with updates n.\n",
    "\n",
    "NB: The weights depend only on $x_i$, not $y_i$ - this means if we are measuring multiple functions on the same spacing, we can reuse the weights, leading to substantial computaitonal savings.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit being that the calucation of the $\\omega_i$, $O(n^2)$ is precomputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barycentric formula\n",
    "\n",
    "We can write one more form which is commonly implemented. Let's add one more piece of data:\n",
    "\n",
    "$$ 1 = \\sum_{j=0}^n P_j = \\Omega(x) \\sum_{j=0}^n \\frac{w_j}{x-x_j}$$\n",
    "\n",
    "then we divide the previous function and write:\n",
    "\n",
    "$$\n",
    "y(x) = \\frac{\\sum_{j = 0}^n \\frac{w_i}{x - x_j} y_i}{\\sum_{j = 0}^n \\frac{w_i}{x - x_j}}\n",
    "$$\n",
    "\n",
    "where we have cancelled $\\Omega$! Besides elegance, his avoids an issue when evaluating $x\\rightarrow x_i$ where roundoff can cause subtractive cancellation. Since the term appears in the numerator and denominator this cancels out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's divided difference method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's polynomial interpolation has the form:\n",
    "\n",
    "$$ y(x) = a_0 + a_1[x-x_0] + a_2 [x-x_0][x-x_1] + \\dots + a_n[x-x_0][x-x_1]\\dots[x-x_n]$$\n",
    "\n",
    "which has the advantage of $O(n)$ evaluations due to recursion and nested multiplication. E.g. for 4 terms,\n",
    "\n",
    "$$ y(x) = a_0 + [x-x_0] \\bigg[a_1  + [x-x_1] \\big[a_2  + [x-x_2] a_3 \\big] \\bigg] $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method is also known as the **divided differences**\n",
    "\n",
    "> This was the algorithm was used to calculate function tables like logarithms and trignometry functions. It was then the basis for the *difference engine*, an early mechanical calculator.\n",
    "\n",
    "Let's pick a data point to start at. Say $y(x_0) = a_0 = y_0$,\n",
    "$$a_0 = y_0$$\n",
    "\n",
    "Add the next data point: $y(x_1) = a_0 + a_1(x_1-x_0) = y_1$, or:\n",
    "\n",
    "$$a_1 = \\frac{y_1 - y_0}{x_1 - x_0}$$\n",
    "\n",
    "Now, insert data point $(x_2, y_2)$,\n",
    "\n",
    "$$a_2 = \\frac{\\frac{y_2 - y_1}{x_2 - x_1} - \\frac{y_1 - y_0}{x_1 - x_0}}{x_2 - x_0}$$\n",
    "\n",
    "and similarly,\n",
    "\n",
    "$$a_3 = \\frac{\\frac{\\frac{y_3-y_2}{x_3-x_2} - \\frac{y_2 - y_1}{x_2-x_1}}{x_3 - x_1} - \\frac{\\frac{y_2-y_1}{x_2-x_1}-\\frac{y_1 - y_0}{x_1 - x_0}}{x_2-x_0}}{x_3 - x_0}$$\n",
    "\n",
    "Notice the recurrsion and the division of the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generalize this. Define the two-argument function:\n",
    "\n",
    "$$ y[x_1, x_0] = \\frac{y_1 - y_0}{x_1 - x_0}$$\n",
    "\n",
    "and the ternary recursively:\n",
    "\n",
    "$$ y[x_2, x_1, x_0] = \\frac{\\frac{y_2 - y_1}{x_2 - x_1} - \\frac{y_1 - y_0}{x_1 - x_0}}{x_2 - x_0} = \\frac{y[x_2,x_1] - y[x_1,x_0]}{x_2-x_1}$$\n",
    "\n",
    "The $n-nary$ function is:\n",
    "\n",
    "$$ y[x_k, x_{k-1}, \\dots, x_{1}, x_0] = \\frac{y[x_k, x_{k-1}, \\dots, x_{2}, x_2] - y[x_{k-1}, x_{k-2}, \\dots, x_{1}, x_0]}{x_k-x_0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this is in a *tableau*:\n",
    "$$\n",
    "\\begin{array}{cccccc}\n",
    "x_0 & y_0 \\\\\n",
    "    &     & y[x_1,x_0] \\\\\n",
    "x_1 & y_1 &             & y[x_2, x_1,x_0]\\\\\n",
    "    &     & y[x_2,x_1]  &              & y[x_3, x_2, x_1,x_0]\\\\\n",
    "x_2 & y_2 &             & y[x_3, x_2,x_1] &             & y[x_4, x_3, x_2, x_1,x_0]\\\\\n",
    "    &     & y[x_3,x_2]  &              & y[x_4, x_3, x_2, x_1]\\\\\n",
    "x_3 & y_3 &             & y[x_4, x_3,x_2]\\\\\n",
    "    &     & y[x_4,x_3] \\\\\n",
    "x_4 & y_4\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "where element is the difference of the two to the left.\n",
    "Alternately, it is sometimes written in the form,  \n",
    "\n",
    "$$\n",
    "\\begin{array}{c||cccccc}\n",
    "x_0 & y_0 & 0 & 0 & 0 & 0\\\\\n",
    "x_1 & y_1 & y[x_1,x_0] & 0 & 0 & 0\\\\\n",
    "x_2 & y_2 & y[x_2,x_1] & y[x_2, x_1,x_0] & 0          & 0 \\\\\n",
    "x_3 & y_3 & y[x_3,x_2] & y[x_3, x_2,x_1] & y[x_3, x_2, x_1,x_0] & 0            \\\\\n",
    "x_4 & y_4 & y[x_4,x_3] & y[x_4, x_3,x_2] & y[x_4, x_3, x_2, x_1]  & y[x_4, x_3, x_2, x_1,x_0]  \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Note that the diagonal is the coefficients that we need, i.e. $a_0, a_1, a_2, a_3, a_4$ for the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, there is a direct solution method that only became really poractical with the advent of modern computing since it focusses on linear systes:\n",
    "\n",
    "Consider fitting a function\n",
    "\n",
    "$$ y(x) = a_n x^n + a_{n-1} x^{n-1} \\dots a_2 x^2 + a_1 x +a_0$$\n",
    "\n",
    "since\n",
    "\n",
    "$y(x_i) = a_n x_i^n + a_{n-1} x_i^{n-1} \\dots a_2 x_i^2 + a_1 x_i +a_0 = y_i$\n",
    "\n",
    "we can write out in matrix form,\n",
    "\n",
    "$$\n",
    " \\begin{bmatrix}\n",
    "1 & x_1 & x_1^2 & \\cdots & x_1^m \\\\\n",
    "1 & x_2 & x_2^2 & \\cdots & x_2^m \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_n & x_n^2 & \\cdots & x_n^m\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a_0 \\\\\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "\\vdots \\\\\n",
    "a_m\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where the matrix of coefficients is called a Vandermonde matrix. This system can be solved for $a_i$ with a dense linear solver. The issue with this method is that the system is notoriously ill-conditioned and roundoff error accumulates rapidly for large $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example: Interpolate our toy problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us know examine our toy problem. Since all the polynomial interpolation functions generate the same unique polynomial, any will suffice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Interpolate the data in x_d and y_d using numpy Legendre, and plot along with the original curve from -5.5 to 5.5\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Interpolate using numpy Legendre\n",
    "coefficients = legendre.legfit(x_d, y_d, len(x_d) - 1)\n",
    "legendre_polynomial = legendre.Legendre(coefficients)\n",
    "\n",
    "# Create x values for plotting the interpolated polynomial\n",
    "x_interp = np.linspace(-5.5, 5.5, 200)\n",
    "y_interp = legendre_polynomial(x_interp)\n",
    "\n",
    "\n",
    "# Plot the original curve, sampled points, and interpolated polynomial\n",
    "plt.plot(x_toy, y_toy, label='exp(-(x/2)^2)')\n",
    "plt.scatter(x_d, y_d, color='red', label='Sampled points')\n",
    "plt.plot(x_interp, y_interp, label='Legendre Interpolation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.title('Function, Sampled Points, and Legendre Interpolation')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YIKES!\n",
    "\n",
    "This is an example of *Runge's phenomenon*: That even for a seeminlgly ideal case of equalspaced samples, higher order polynomials can show huge oscillations between samples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The order that the datapoints are added is arbitrary but will result in a different tableau (with the same diagonal).\n",
    "* We can build this matrix / tableau diagonal-by-diagonal which means adding new data points doesn't require recalculation of the others.\n",
    "* Each new diagonal (datapoint) takes $O(n)$ so assembly of the tableau takes $~O(n^2)$.\n",
    "* Evaluation of f(x) takes $O(n)$\n",
    "* These coefficients are independant of $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recap and generalize:\n",
    "* For any $n$ points there is a polynomial that fits it, but because of Runge's phenomenon you don't want to use that!\n",
    "* Piecewise polynomials are *stiffer* and avoids Runge's phenomenon, but smoothness causes issues for N-D\n",
    "So what do we do? Standard pacakges offer simplistic but pragmatic interpolators (optimized for either rectangular or irregular grids) :\n",
    "* Nearest ND interpolator: Find the nearest data point and use that.\n",
    "* Linear ND interpolators: For each input, a triangulation finds the nearest data points and a linear barycentric Lagrange interpolation is performed.\n",
    "\n",
    "Neither of these are completely satisfactory, so we will have to respost to more advanced methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
