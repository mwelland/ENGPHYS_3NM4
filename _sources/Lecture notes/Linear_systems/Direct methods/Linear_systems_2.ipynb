{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPabfmrCOt2/nh/Dfa1bij5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwelland/ENGPYHS_3NM4/blob/main/Linear_systems_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goals\n",
        "- Describe the computational complexity of algorithms\n",
        "- Formalize how we solve linear systems\n",
        "- Show how to transform general linear systems into simpler triangular systems with Gauss Elimination\n",
        "- Demonstrate the importance of pivoting and define diagonal dominance"
      ],
      "metadata": {
        "id": "njzEoGIZaeAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computational complexity\n",
        "The *computational complexity* of an algorithm characterizes the number of operations it requires (thus comparing the algorithm instead of the hardware). Linear algebra algorithms are characterized in terms of the dimension of their arguments (vector length, matrix size, etc). Complexity is represented in big O notation (similar to the accuracy of function approximations). I.e.: Only the leading order is kept, and constants disregarded.\n",
        "\n"
      ],
      "metadata": {
        "id": "YWl1eF9gGfps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example\n",
        "Traditional matrix multiplication of two $n \\times n$ matricies - involves $n^3$ operations and is thus $O(n^3)$\n",
        "\n",
        "NB: This is algorithm-dependant - The Strassen algorithm has $O(n^{2.81})$"
      ],
      "metadata": {
        "id": "kNnkXY9_IT85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_matmult(n):\n",
        "  import numpy as np\n",
        "  A = np.random.rand(n, n)\n",
        "  B = np.random.rand(n, n)\n",
        "  %timeit C = A @ B\n",
        "\n",
        "time_matmult(100)\n",
        "time_matmult(1000)\n",
        "time_matmult(2000)\n",
        "time_matmult(4000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40mLSY5b2ld_",
        "outputId": "a6e200c3-f5fe-4fd9-f8a9-29793c347042"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123 µs ± 51.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
            "98.4 ms ± 37.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "514 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "4.64 s ± 736 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some complexities of common linear algebra operations:\n",
        "\n",
        "| Operation | Description | Complexity |\n",
        "|---|---|---|\n",
        "| Matrix addition | Adding two matrices of the same size | O(n²) |\n",
        "| Matrix multiplication | Multiplying two matrices | O(n³) (standard algorithm) |\n",
        "| Matrix-vector multiplication | Multiplying a matrix by a vector | O(n²) |\n",
        "| Matrix inversion | Finding the inverse of a matrix | O(n³) |\n",
        "| Determinant calculation | Computing the determinant of a matrix | O(n³) |\n",
        "| Transpose | Swapping rows and columns of a matrix | O(n²) |\n",
        "| Matrix norm| Sqrt of sum of squares | O(n²) |"
      ],
      "metadata": {
        "id": "qf_2lHRXKn3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-performance computing introduces a new element to complexity which deals with how algorithms parallelize. This is called *scaling* and measured in $O(number \\ of \\ nodes)$. The goal is usually $O(n)$ but is hard to achieve!"
      ],
      "metadata": {
        "id": "7Rsw2EUkQ_YS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Solving linear systems with Gauss elimination"
      ],
      "metadata": {
        "id": "8DvVp7AAAeD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gauss elimination is an algorithm for the most familiar / intuitive solution technique. Let's reexamine our analytical (symbolic) solution to the previous problem and then make it into a numerical algorithm."
      ],
      "metadata": {
        "id": "YubyaVXHAmnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:\n",
        "You are organizing a fundraising event and need to buy chairs and tables. Chairs cost \\$20 each and tables cost \\$50 each. You have a budget of \\$700 and need a total of 20 pieces of furniture (chairs and tables combined). How many chairs and tables should you buy?"
      ],
      "metadata": {
        "id": "yWyxdki_BPUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Symbolic manipulation\n",
        "\n",
        "Let $c$ and $t$ be the number of chairs and tables respectively.\n",
        "\n",
        "The budget and pieces equations are,\n",
        "\n",
        "(1) $20 c + 50 t = 700$\n",
        "\n",
        "(2) $  c+t = 20$"
      ],
      "metadata": {
        "id": "48_mK3wxBVyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve (2) for $c$:\n",
        "\n",
        "$c = 20-t$\n",
        "\n",
        "Substitute into (1):\n",
        "\n",
        "$20 [20-t] + 50t = 700$\n",
        "\n",
        "$t = 10$\n",
        "\n",
        "and substitute into (2) or (1) to find $c$.\n",
        "\n",
        "This works because our first step carries the unkown *symbol* $t$."
      ],
      "metadata": {
        "id": "JnpMRYBtBeTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numerical approach\n",
        "\n",
        "Lets repeat this without carrying symbols.\n",
        "\n",
        "(1) $20 c + 50 t = 700$\n",
        "\n",
        "(2) $  c+t = 20$\n",
        "\n",
        "Multiply (2) by $20$:\n",
        "\n",
        "$20 c + 20 t = 400$\n",
        "\n",
        "and subtract from (1):\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "20 c + &50 t  &=& 700 \\\\\n",
        "-20 c - &20 t &=& -400 \\\\\n",
        "\\hline\n",
        " &30 t &=& 300\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Thus we have simplified the last line until it reaches a trival solution for $t$. Now it is a matter of *substitution* to solve for $c$.\n"
      ],
      "metadata": {
        "id": "qFAu4hCXCera"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the linear system has been changed (without changing the answer) to:\n",
        "\n",
        "$\\begin{pmatrix}\n",
        "20 & 50 \\\\\n",
        "0 & 30\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "c \\\\\n",
        "t\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}\n",
        "700 \\\\\n",
        "300\n",
        "\\end{pmatrix}$\n",
        "\n",
        "In particular, $A$ is *upper triangular*, (aka *row echelon form* for a square matrix) from which the answer is easily obtained through *backward substitution*."
      ],
      "metadata": {
        "id": "FAM19Bp_ZVAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upper triangular matricies\n",
        "\n",
        "An upper triangular matrix, $U$, is a matrix whose elements below the diagonal are zero:\n",
        "\n",
        "$$\\begin{bmatrix}\n",
        "u_{1,1} & u_{1,2} & u_{1,3} & u_{1,4}\\\\\n",
        "0 & u_{2,2}' & u_{2,3}' & u_{2,4}'\\\\\n",
        "0 & 0 & u_{3,3}' & u_{3,4}' \\\\\n",
        "0 & 0 & 0 & u_{4,4}'\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "This is useful because, in equation form,\n",
        "\n",
        "$U x = b'$\n",
        "\n",
        "turns in to\n",
        "\\begin{eqnarray*}\n",
        "\\begin{array}{}\n",
        " u_{1,1} x_1 &+& u_{1,2} x_2 & + & u_{1,3} x_{3} &+&u_{1,4} x_4 &=& b'_1,\\\\\n",
        "& & u_{2,2}' x_{2} &+ & u_{2,3}' x_{3} &+& u_{2,4}' x_4 &=& b_{2}' \\\\\n",
        "&& & & u_{3,3}' x_{3} &+& u_{3,4}' x_4 &=& b_{3}',\\\\\n",
        "&& && && u_{4,4}' x_4 &=& b_{4}'.\n",
        "\\end{array}\n",
        "\\end{eqnarray*}"
      ],
      "metadata": {
        "id": "v4GBuvT0slw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "which can be solved in $O(n^2)$ time!"
      ],
      "metadata": {
        "id": "Z548bgMY4NPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gauss Elimination\n",
        "\n",
        "Gauss Elimination proceeds in two phases. The first is elimination which transforms\n",
        "\n",
        "$A x = b$\n",
        "\n",
        "into\n",
        "\n",
        "$U x = b'$\n",
        "\n",
        "where $U$ is an upper triangular matrix and $b'$ is a modified vector of constants. The second phase is back-substitution which is trivial with triangular matricies."
      ],
      "metadata": {
        "id": "g_WY_oMAZsQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gauss elimination algorithm\n",
        "\n",
        "We first take\n",
        "\n",
        "$Ax = b$\n",
        "\n",
        "and build an *Augmented matrix*:\n",
        "\n",
        "$Ab = [ A | b ]$\n",
        "\n",
        " We are allowed the following operations which affect $|A|$ but not the solution to the problem:\n",
        "\n",
        "|Operation | Effect on $|A|$ |\n",
        "|-----|-----|\n",
        "|Exchange 2 rows | Flips sign|\n",
        "|Multiply a row by § | Multiplied by § |\n",
        "|Subtract 2 rows     | Unchanged|"
      ],
      "metadata": {
        "id": "UYC-PAVaDwqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Steps from our previous example"
      ],
      "metadata": {
        "id": "qfMYLZ_pbkdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Define A and b\n",
        "\n",
        "A = np.array([[20, 50],\n",
        "              [1, 1]])\n",
        "\n",
        "b = np.array([[700], [20]])\n",
        "\n",
        "#Form the augmented matrix A|b\n",
        "Ab = np.hstack([A, b])\n",
        "\n",
        "#The coefficient matrix can be separated by slicing Ab\n",
        "def print_update():\n",
        "  print(\"Augmented matrix is \\n\", Ab)\n",
        "  print(\"Determinant of A: \", np.linalg.det(Ab[:,:-1])),\n",
        "  print(\"Norm of A\", np.linalg.norm(Ab[:,:-1], 'fro')),\n",
        "  print(\"Condition number of A:\", np.linalg.cond(Ab[:, :-1]))\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(\"Step 0: Show the augmented matrix and the determinant of A\")\n",
        "print_update()\n",
        "\n",
        "print(\"Step 1: Multiply the second row by 20\")\n",
        "Ab[1, :] = Ab[1, :] * 20\n",
        "print_update()\n",
        "\n",
        "print(\"Step 2: Subtract the second row from the first\")\n",
        "Ab[1, :] = Ab[1, :] - Ab[0, :]\n",
        "print_update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgi4vBeXF1_P",
        "outputId": "a69dfaa6-601a-45b4-bfec-56af7cc3cc89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: Show the augmented matrix and the determinant of A\n",
            "Augmented matrix is \n",
            " [[ 20  50 700]\n",
            " [  1   1  20]]\n",
            "Determinant of A:  -29.99999999999999\n",
            "Norm of A 53.87021440462252\n",
            "Condition number of A: 96.72299453018881\n",
            "\n",
            "\n",
            "Step 1: Multiply the second row by 20\n",
            "Augmented matrix is \n",
            " [[ 20  50 700]\n",
            " [ 20  20 400]]\n",
            "Determinant of A:  -600.0\n",
            "Norm of A 60.8276253029822\n",
            "Condition number of A: 6.000000000000001\n",
            "\n",
            "\n",
            "Step 2: Subtract the second row from the first\n",
            "Augmented matrix is \n",
            " [[  20   50  700]\n",
            " [   0  -30 -300]]\n",
            "Determinant of A:  -600.0\n",
            "Norm of A 61.644140029689765\n",
            "Condition number of A: 6.171292729553326\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The determinant, norm and condition number are all changing despite the answer remaining the same. This is the basis of preconditioners!"
      ],
      "metadata": {
        "id": "RWIEeTtqvdNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Algorithm\n",
        "\n"
      ],
      "metadata": {
        "id": "CGcRybA6bg3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's describe an algorithm for Gaussian elimination, as a sequence of passes row by row through the matrix.\n",
        "\n",
        "Each pass we choose a *pivot row* which is used to eliminate the elements in other equations through multiplication of the pivot and subtraction.\n",
        "\n",
        "Start from the top and only pass downwards, so we end up with an upper triangular matrix."
      ],
      "metadata": {
        "id": "rtzcmy2HxUba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Example\n",
        "\n",
        "Use Gauss Elimination to solve the following equations.\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "4x_1 + 3x_2 - 5x_3 &=& 2 \\\\\n",
        "-2x_1 - 4x_2 + 5x_3 &=& 5 \\\\\n",
        "8x_1 + 8x_2  &=& -3 \\\\\n",
        "\\end{eqnarray*}"
      ],
      "metadata": {
        "id": "aWBYESevcq9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Turn these equations to matrix form $Ax=y$.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5\\\\\n",
        "-2 & -4 & 5\\\\\n",
        "8 & 8 & 0\\\\\n",
        "\\end{bmatrix}\\left[\\begin{array}{c} x_1 \\\\x_2 \\\\x_3 \\end{array}\\right] =\n",
        "\\left[\\begin{array}{c} 2 \\\\5 \\\\-3\\end{array}\\right]$$"
      ],
      "metadata": {
        "id": "V4MRmE2Bcw-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Get the augmented matrix [A, y]\n",
        "\n",
        "$$\n",
        "[A, y]  = \\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "-2 & -4 & 5 & 5\\\\\n",
        "8 & 8 & 0 & -3\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "-j_g6SSOc0M8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Choose the first equation as the pivot equation and turn the 2nd row first element to 0. To do this, we can multiply -0.5 for the 1st row (pivot equation) and subtract it from the 2nd row. The multiplier is $m_{2,1}=-0.5$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "8 & 8 & 0 & -3\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "6j6iWcr0c1DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Turn the 3rd row first element to 0. We can do something similar, multiply 2 to the 1st row and subtract it from the 3rd row. The multiplier is $m_{3,1}=2$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "0 & 2 & 10 & -7\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "ZuQHvY0Gc5Cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Turn the 3rd row 2nd element to 0. We can multiple -4/5 for the 2nd row, and subtract it from the 3rd row. The multiplier is $m_{3,2}=-0.8$. We will get\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 & 2\\\\\n",
        "0 & -2.5 & 2.5 & 6\\\\\n",
        "0 & 0 & 12 & -2.2\\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "g9ALF2Zpc9Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elmination is now complete since $A$ is upper triangular.\n",
        "\n",
        "Proceed with substitution:\n",
        "\n",
        "Step 6: Therefore, we can get $x_3=-2.2/12=-0.183$.\n",
        "\n",
        "Step 7: Insert $x_3$ to the 2nd equation, we get $x_2=-2.583$\n",
        "\n",
        "Step 8: Insert $x_2$ and $x_3$ to the first equation, we have $x_1=2.208$."
      ],
      "metadata": {
        "id": "dmEMlmYRc_wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complexity\n",
        "\n",
        "Considering the two phases of Gauss elimination:\n",
        "\n",
        "Elimination: ~$n^3/3$ operations, therefore, $O(n^3)$\n",
        "\n",
        "Back substitution: ~ $n^2/2$ operations, therefore $O(n^2)$\n"
      ],
      "metadata": {
        "id": "XxXtEjqzLxJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gauss-Jordan Elimination\n",
        "An obvious extension is to conduct each pass both upwards and downwards (G.E. is just down). While doing this we also normalize the row to get reduced row echelon form (abbreviated: rref):\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 & 2.208\\\\\n",
        "0 & 1 & 0 & -2.583\\\\\n",
        "0 & 0 & 1 & -0.183\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Since $I^{-1} = I$, the answer is just the right hand vector."
      ],
      "metadata": {
        "id": "g1T61zk3uHjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complexity\n",
        "Gauss-Jordan Elimination eliminates the need for back-substitution so one might think that it is more efficient than Gauss Elimination. Unfortunatley, the elimination phase takes ~$~n^3/2$ operations whereas GE took ~$n^3/3 + n^2/2$. therefore Gauss Elimination is preferred."
      ],
      "metadata": {
        "id": "M1g9YM2tMbwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Package implementation\n",
        "\n",
        "Gaussian Elimination is fundamental but has largely been surpased by matrix decomposition (We will see the connection soon). Therefore, you will be hard pressed to find a standard implemention in numperical packages (numpy / scipy).\n",
        "\n",
        "It is still useful in symbolic manipulation, and indeed you will find it in *sympy* under *echelon form* and *rref*:"
      ],
      "metadata": {
        "id": "7n7TOKRAifdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt: Use sympy rref and echelon form to make an example for linear system\n",
        "\n",
        "from sympy import Matrix, symbols, pprint\n",
        "\n",
        "a = symbols('a')\n",
        "\n",
        "# Define the coefficient matrix and the right-hand side vector\n",
        "A = Matrix([[1, 2, 3],\n",
        "            [4, 5, 6],\n",
        "            [7, 8, 9]])\n",
        "b = Matrix([2, 5, -3])\n",
        "\n",
        "# Combine the coefficient matrix and the right-hand side vector into an augmented matrix\n",
        "Ab = A.row_join(Matrix(b))\n",
        "\n",
        "# Calculate the reduced row echelon form (rref) of the augmented matrix\n",
        "Ab_rref = Ab.rref()\n",
        "\n",
        "# Print the result\n",
        "print(\"Augmented matrix in rref:\")\n",
        "pprint(Ab_rref[0])\n",
        "\n",
        "# Calculate the echelon form of the coefficient matrix\n",
        "Ab_echelon = Ab.echelon_form()\n",
        "\n",
        "# Print the result\n",
        "print(\"\\nCoefficient matrix in echelon form:\")\n",
        "pprint(Ab_echelon)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSv3YJaFmjVw",
        "outputId": "0ef482da-ba60-4e06-9e26-a1ed7a9b9573"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented matrix in rref:\n",
            "⎡1  0  -1  0⎤\n",
            "⎢           ⎥\n",
            "⎢0  1  2   0⎥\n",
            "⎢           ⎥\n",
            "⎣0  0  0   1⎦\n",
            "\n",
            "Coefficient matrix in echelon form:\n",
            "⎡1  2   3   2 ⎤\n",
            "⎢             ⎥\n",
            "⎢0  -3  -6  -3⎥\n",
            "⎢             ⎥\n",
            "⎣0  0   0   33⎦\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pivoting and diagonal dominance\n",
        "\n"
      ],
      "metadata": {
        "id": "FzKC2Byc0mrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The order of equations, and therefore rows in the matrix, is obviously arbitrary, but this may break Gauss Elimination.\n",
        "\n",
        "E.g.: a system with augmented matrix\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "2 & -1 & 0 & 1\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "0 & -1 & 1 & 0\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "will work with our GE scheme, but the same system reordered,\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "0 & -1 & 1 & 0\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "2 & -1 & 0 & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "will fail due to the $0$ in the element of the first row. The remedy is to swap rows 3 and 1 to match the first example."
      ],
      "metadata": {
        "id": "877cpzFQ1kM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Permutation matrix\n",
        "Swapping rows in matrix algebra is achieved via a *permutation matrix* (row swap of the *identity matrix*).\n",
        "\n",
        "To swap rows 3 and 1, we would use:\n",
        "\n",
        "$$\n",
        "P =\n",
        "\\begin{bmatrix}\n",
        "0 & 0 & 1 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "1 & 0 & 0 \\\\\n",
        "\\end{bmatrix}$$\n"
      ],
      "metadata": {
        "id": "SCmjF9smwxuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diagonal dominance\n",
        "\n"
      ],
      "metadata": {
        "id": "wVzt8kXh4pAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More generally, if the diagonal element is *small* we will encounter roundoff error:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\epsilon & -1 & 1 & 0\\\\\n",
        "-1 & 2 & -1 & 0\\\\\n",
        "2 & -1 & 0 & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "after the first pass leads to:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "\\epsilon & -1 & 1 & 0\\\\\n",
        "-1 & 2 -1/\\epsilon & -1 + 1/\\epsilon & 0\\\\\n",
        "2 & -1 -1/\\epsilon& + 1/\\epsilon & 1\\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "from which we immediately see the danger as $\\epsilon \\rightarrow 0$!"
      ],
      "metadata": {
        "id": "-MTl4rcz32Ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, we don't want the diagonal to have $0$s or *small* numbers. This motivates the definition of *diagonal dominance*.\n",
        "\n",
        "A matrix is said to be *diagonally dominant* if each diagonal is larger, in absolute value, than the *sum of the other elements in the row*.\n",
        "\n",
        "$|A_{ii}| \\ge \\sum_{j=1,j \\ne i}^{n} |A_{ij}|$\n",
        "\n"
      ],
      "metadata": {
        "id": "gnhiWE4UxrPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Which is diagonally dominant?\n",
        "\n",
        "a) $$\n",
        "\\begin{bmatrix}\n",
        "-2 & 4 & -1 \\\\\n",
        "-1 & -1 & 3 \\\\\n",
        "4 & -2 & 1 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "b)\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "4 & -2 & 1 \\\\\n",
        "-2 & 4 & -1 \\\\\n",
        "-1 & -1 & 3 \\\\\n",
        "\\end{bmatrix}$$"
      ],
      "metadata": {
        "id": "g4Vv_A3858SK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importance of diagonal dominance\n",
        "It can be shown that if a matrix is diagonally dominant, *it will not benefit from pivoting!*.\n",
        "\n",
        "Diagonal dominance contributes generally to numerical stability and accuracy through minimizing roundoff error propogation. This result extends beyond Gauss elimination, and will also be a criteria for matrix factorization methods and the efficient convergence of iterative methods."
      ],
      "metadata": {
        "id": "kcVtBeJ67o8Y"
      }
    }
  ]
}