{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwZZirxA8hJv"
      },
      "source": [
        "# LU decomposition\n",
        "\n",
        "Commonly we will have to repeatedly solve\n",
        "$Ax = b$ for multiple $b_i$. Gauss Elimination for each $b_i$ would be grossly inefficient. If you knew all the $b_i$ in advance you could do this in parallel by forming the augmented matrix:\n",
        "\n",
        "$[A|b_1 \\ b_2 \\  b_3 \\ ...]$\n",
        "\n",
        "but this is seldom the case.\n",
        "\n",
        "It is much more efficient to decompose the matrix $A$ into a form that is easier to solve.\n",
        "\n",
        "> There are other reasons to do this for special matrix types and distributed computing which we will discuss later.\n",
        "\n",
        "We have actually already seen this efficiency boost with back-substitution. The equation $U x = b$ solves in $O(n^2)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CThm-lm88mwc"
      },
      "source": [
        "Any square matrix can be decomposed,\n",
        "\n",
        "$A = LU$\n",
        "\n",
        "where:\n",
        "\n",
        "$L$ is a lower triangular matrix\n",
        "\n",
        "$U$ is an upper triangular matrix\n",
        "\n",
        "Now, the linear system becomes:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "Ax &= b \\\\\n",
        "LUx &= b\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Now let $y = Ux$, such that\n",
        "\n",
        "$$\\begin{align}\n",
        "Ly &= b \\\\\n",
        "Ux &= y\n",
        "\\end{align} $$\n",
        "both of which solve in $O(n^2)$.\n",
        "\n",
        "NOTE: L and U are generally *not unique*.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmuC4gf-vBeD"
      },
      "source": [
        "Example: Return to the previouis example:\n",
        "\n",
        "\\begin{align}\n",
        "4x_1 + 3x_2 - 5x_3 &=& 2 \\\\\n",
        "-2x_1 - 4x_2 + 5x_3 &=& 5 \\\\\n",
        "8x_1 + 8x_2  &=& -3 \\\\\n",
        "\\end{align}\n",
        "\n",
        "Through Gaussian Elimination, we found\n",
        "\n",
        "$$ U=\n",
        "\\begin{bmatrix}\n",
        "4 & 3 & -5 \\\\\n",
        "0 & -2.5 & 2.5 \\\\\n",
        "0 & 0 & 12 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "by clearing the first column by multiplying the first row by $-0.5$ for the second row, and  $2$ for the third. The second column was cleared with the second row multiplied by $-0.8$. These coefficients turn out to be the elemements of the $L$ matrix (with 1's along the diagonal)!\n",
        "\n",
        "$$ L=\n",
        "\\begin{bmatrix}\n",
        "1 & 0 & 0 \\\\\n",
        "-0.5 & 1 & 0 \\\\\n",
        "2 & -0.8 & 1 \\\\\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Let's verify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP0Af5Ztv35r",
        "outputId": "6f01e34e-9b3f-4cf2-9cde-18bd66a919f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The original matrix A is:\n",
            " [[ 4  3 -5]\n",
            " [-2 -4  5]\n",
            " [ 8  8  0]] \n",
            "\n",
            "The reconstructed matrix is:\n",
            " [[ 4.  3. -5.]\n",
            " [-2. -4.  5.]\n",
            " [ 8.  8.  0.]]\n"
          ]
        }
      ],
      "source": [
        "# prompt: Do decomposition on the above matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Define the matrix A\n",
        "A = np.array([[4, 3, -5],\n",
        "              [-2, -4, 5],\n",
        "              [8, 8, 0]])\n",
        "\n",
        "print(\"The original matrix A is:\\n\", A, \"\\n\")\n",
        "L = np.array([[1,0,0],\n",
        "               [-.5, 1,0],\n",
        "               [2,-.8,1]])\n",
        "\n",
        "U = np.array([[4,3,-5],\n",
        "              [0,-2.5,2.5],\n",
        "              [0,0,12]])\n",
        "\n",
        "print(\"The reconstructed matrix is:\\n\", L@U)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4wtwinxR3vd"
      },
      "source": [
        "Let's check the package decomposition!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12yze0ctR2vy",
        "outputId": "3f2b4514-efb0-468c-e9ea-87f27af12759"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Permutation Matrix (P):\n",
            " [[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n",
            "Lower Triangular Matrix (L):\n",
            " [[ 1.    0.    0.  ]\n",
            " [-0.25  1.    0.  ]\n",
            " [ 0.5   0.5   1.  ]]\n",
            "Upper Triangular Matrix (U):\n",
            " [[ 8.   8.   0. ]\n",
            " [ 0.  -2.   5. ]\n",
            " [ 0.   0.  -7.5]]\n",
            "\n",
            "Multiply L and U:\n",
            " [[ 8.  8.  0.]\n",
            " [-2. -4.  5.]\n",
            " [ 4.  3. -5.]] \n",
            "which is correct but pivoted!\n",
            "\n",
            "Multiply PLU:\n",
            " [[ 4.  3. -5.]\n",
            " [-2. -4.  5.]\n",
            " [ 8.  8.  0.]] \n",
            "which is the original matrix!\n"
          ]
        }
      ],
      "source": [
        "# Calculate the LU decomposition\n",
        "from scipy.linalg import lu, inv\n",
        "P, L, U = lu(A)\n",
        "\n",
        "print(\"Permutation Matrix (P):\\n\", P)\n",
        "print(\"Lower Triangular Matrix (L):\\n\", L)\n",
        "print(\"Upper Triangular Matrix (U):\\n\", U)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nMultiply L and U:\\n\", L@U, \"\\nwhich is correct but pivoted!\")\n",
        "\n",
        "print(\"\\nMultiply PLU:\\n\", P@L@U, \"\\nwhich is the original matrix!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Ro4bk8y-C1"
      },
      "source": [
        "NB: $P$ in the above is the permutation matrix that, when multiplied by LU recovers the original matrix. It is *not* the pivoting operation that is done internally (although that matrix is easily obtained!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P5RjZcxmXRA"
      },
      "source": [
        "# Dr. Mike's Tips!\n",
        "\n",
        "- Direct solver are your 'black box' for most of your needs.\n",
        "- They are the most robust for ill-conditioned systems.\n",
        "- They scale *terribly* (both in system size and parallelization)\n",
        "- If you use them, start with a small system and work upwards.\n",
        "- Generally speaking you won't see a speedup with parallelization until you get a large # of nodes\n",
        "- Warning: Some implementations (numpy) are sophisticated enough to handle singular matricies as well as non-singular (be careful with the answer!)\n",
        "- Sparse matricies are your saving grace! Do your best to protect them (hence store the LU factors, not the inverse!)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOXPvbhaXScY2V34w1nuBQy",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}